{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import json\n",
    "\n",
    "with open('data/gg2013.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Convert the JSON data to a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Extract user information into separate columns\n",
    "df['user_screen_name'] = df['user'].apply(lambda x: x['screen_name'])\n",
    "df['user_id'] = df['user'].apply(lambda x: x['id'])\n",
    "\n",
    "# Drop the original 'user' column as we've extracted the needed information\n",
    "df = df.drop('user', axis=1)\n",
    "\n",
    "# Convert timestamp_ms to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp_ms'], unit='ms')\n",
    "\n",
    "# Drop the original timestamp_ms column\n",
    "df = df.drop('timestamp_ms', axis=1)\n",
    "\n",
    "# Reorder columns for better readability\n",
    "df = df[['id', 'timestamp', 'user_id', 'user_screen_name', 'text']]\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "# print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to apply regex patterns and extract potential winners\n",
    "def extract_winners(text, award):\n",
    "    # Improved regex to properly handle 'just' variations\n",
    "    just_variations = r'(?:(?:(?:she|he)\\s+)?just\\s+)?'\n",
    "    winner_patterns = [\n",
    "        r'(\\w+(?:\\s+\\w+)?)\\s+' + just_variations + r'wins\\s+(?!' + award + ')',\n",
    "        r'(\\w+(?:\\s+\\w+)?)\\s+' + just_variations + r'won\\s+(?!' + award + ')',\n",
    "        r'(\\w+(?:\\s+\\w+)?)\\s+' + just_variations + r'awarded\\s+(?!' + award + ')',\n",
    "        r'(\\w+(?:\\s+\\w+)?)\\s+' + just_variations + r'receives\\s+(?!' + award + ')',\n",
    "        r'(\\w+(?:\\s+\\w+)?)\\s+' + just_variations + r'received\\s+(?!' + award + ')'\n",
    "    ]\n",
    "    winners = []\n",
    "    for pattern in winner_patterns:\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "        winners.extend(matches)\n",
    "    return winners\n",
    "\n",
    "# Apply the extraction function to the 'text' column\n",
    "df['potential_winners'] = df['text'].apply(lambda x: extract_winners(x, \"Best Picture\"))\n",
    "\n",
    "# Print all non-NaN values in the potential_winners column\n",
    "all_winners = df['potential_winners'].dropna()\n",
    "winner_counts = {}\n",
    "for winners in all_winners:\n",
    "    if winners:  # Check if the list is not empty\n",
    "        for winner in winners:\n",
    "            if winner in winner_counts:\n",
    "                winner_counts[winner] += 1\n",
    "            else:\n",
    "                winner_counts[winner] = 1\n",
    "\n",
    "# Create the JSON structure\n",
    "output = {\n",
    "    \"Award\": \"Best Picture\",\n",
    "    \"Nominees\": [],  # We don't have nominee information in the current data\n",
    "    \"Presenters\": [],  # We don't have presenter information in the current data\n",
    "    \"Winner\": [\n",
    "        {\n",
    "            \"Name\": winner,\n",
    "            \"Number of Tweets\": count\n",
    "        } for winner, count in winner_counts.items()\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Sort the winners by number of tweets in descending order\n",
    "output[\"Winner\"] = sorted(output[\"Winner\"], key=lambda x: x[\"Number of Tweets\"], reverse=True)\n",
    "\n",
    "# print(json.dumps(output, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "assume nothing about outputs\n",
    "\n",
    "from winners list, identify candidates who fit type restrictions\n",
    "\n",
    "store in nominees - check against 2013 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type constraints:\n",
    "- eliminate pronouns, random phrases\n",
    "\n",
    "Goal(s):\n",
    "- Map entities to names/nicknames -> map should contain entity names in some standard format (First, Last) \n",
    "- Map entities to some quantity of popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt at entity recognition from \"winners\" list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      3\u001b[0m winners \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWinner\u001b[39m\u001b[38;5;124m\"\u001b[39m], key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of Tweets\u001b[39m\u001b[38;5;124m\"\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m spacy_model \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men_core_web_lg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# better entity recognition capability than en_core_web_sm\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# {\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     Name : _,\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     Entities : []\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[1;32m     11\u001b[0m entity_list \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/TweetMiner/TweetMiner/lib/python3.11/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\n\u001b[1;32m     28\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     35\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[1;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/TweetMiner/TweetMiner/lib/python3.11/site-packages/spacy/util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "winners = sorted(output[\"Winner\"], key=lambda x: x[\"Number of Tweets\"], reverse=True)\n",
    "\n",
    "spacy_model = spacy.load('en_core_web_lg') # better entity recognition capability than en_core_web_sm\n",
    "\n",
    "# {\n",
    "#     Name : _,\n",
    "#     Entities : []\n",
    "# }\n",
    "entity_list = []\n",
    "\n",
    "for i in range(len(winners)):\n",
    "    winner_name = winners[i][\"Name\"]\n",
    "    spacy_output = spacy_model(winner_name)\n",
    "    # print(f\"spacy output: {spacy_output.ents}\")\n",
    "    # if spacy_output.ents == (): print(\"NO ENTITY IDENTIFIED\")\n",
    "    associated_entities = []\n",
    "    for entity in spacy_output.ents:\n",
    "        # print(f\"entity:{entity}\")\n",
    "        # print([entity.text, entity.label_])\n",
    "        # entity_list.append(entity.text)\n",
    "        associated_entities.append(entity.text)\n",
    "    \n",
    "    name_entities = {\n",
    "        \"Name\" : winner_name,\n",
    "        \"Entities\" : associated_entities\n",
    "    }\n",
    "    \n",
    "    entity_list.append(name_entities)\n",
    "    \n",
    "for i in range(30): print(entity_list[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Entity List to check against:\n",
    "- hard coding testing purposes, eventually will need to extract these too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENTITIES = []\n",
    "\n",
    "# for entry in entity_list:\n",
    "#     if len(entry['Entities']) > 0: ENTITIES.append(entry['Entities']) \n",
    "\n",
    "ENTITIES = [\n",
    "    'Ben Affleck', \n",
    "    'Anne Hathaway', \n",
    "    'Julianne Moore', \n",
    "    'Adele', \n",
    "    'Jessica Chastain', \n",
    "    'Daniel Day-Lewis', \n",
    "    'Denzel Washington', \n",
    "    'Jonah Hill', \n",
    "    'Brad Pitt', \n",
    "    'Amy Poehler'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CLUSTERING**\n",
    "\n",
    "Many names may be associated with a given entity\n",
    "- Identify names \"similar\" to the entity (ex: Anne Hathaway - anne hathaway, @annehathaway, etx )\n",
    "- Note that not every string may be mapped to an entity\n",
    "\n",
    "Quantifing \"similarity\" between strings i.e. string distance?\n",
    "- token overlap -> # times each word in string appears in each defined entity, return highest entity\n",
    "- loads of string metrics (https://en.wikipedia.org/wiki/String_metric) -> levenshtein, hamming, jaccard, etx (https://www.nltk.org/api/nltk.metrics.html#module-nltk.metrics.distance)\n",
    "- considerations for string metrics: some metrics require comparison of strings of identical length (ex: Hamming dist.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Token Overlap\n",
    "- https://stackoverflow.com/questions/10136077/python-natural-language-processing-for-named-entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anne Hathaway']\n"
     ]
    }
   ],
   "source": [
    "def token_overlap(query_string, classes):\n",
    "    \"\"\"\n",
    "    Computes the most \"likely\" class for the given query string.\n",
    "\n",
    "    First normalises the query to lower case, then computes the number of\n",
    "    overlapping tokens for each of the possible classes.\n",
    "\n",
    "    The class(es) with the highest overlap are returned as a list.\n",
    "\n",
    "    \"\"\"\n",
    "    query_tokens = query_string.lower().split() # lowercase query\n",
    "    class_tokens = [[x.lower() for x in c.split()] for c in classes] # lowercase each class in CLASSES\n",
    "    # print(f\"tokens:{class_tokens}\")\n",
    "\n",
    "\n",
    "    overlap = [0] * len(classes) # num times each word in query string appears for each defined CLASS \n",
    "    # check overlap on word/token level, not char\n",
    "    for token in query_tokens:\n",
    "        for index in range(len(classes)): \n",
    "            if token in class_tokens[index]:\n",
    "                overlap[index] += 1\n",
    "\n",
    "    # print(overlap)\n",
    "\n",
    "    sorted_overlap = [(count, index) for index, count in enumerate(overlap)]\n",
    "    sorted_overlap.sort()\n",
    "    sorted_overlap.reverse()\n",
    "\n",
    "    best_count = sorted_overlap[0][0]\n",
    "\n",
    "    best_classes = []\n",
    "    for count, index in sorted_overlap:\n",
    "        if count == best_count and count > 0: # count > 0 -> DON'T FORCE MAPPING IF NO OVERLAP WITH ANY ENTITY\n",
    "            best_classes.append(classes[index]) # (classes[index], count) to get token overlap count\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return best_classes\n",
    "\n",
    "\n",
    "print(token_overlap(\"hathaway, anne\", classes=ENTITIES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: Ben Affleck | Similarity: 0.75\n",
      "Entity: Anne Hathaway | Similarity: 0.6\n",
      "Entity: Julianne Moore | Similarity: 0.7058823529411765\n",
      "Entity: Adele | Similarity: 0.9285714285714286\n",
      "Entity: Jessica Chastain | Similarity: 0.3076923076923077\n",
      "Entity: Daniel Day-Lewis | Similarity: 0.6470588235294118\n",
      "Entity: Denzel Washington | Similarity: 0.5294117647058824\n",
      "Entity: Jonah Hill | Similarity: 0.6666666666666666\n",
      "Entity: Brad Pitt | Similarity: 0.7333333333333333\n",
      "Entity: Amy Poehler | Similarity: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.metrics import edit_distance, jaccard_distance\n",
    "\n",
    "str = \"chastain, jessica\"\n",
    "dist_measure = 0\n",
    "\n",
    "for entity in ENTITIES:\n",
    "    similarity = jaccard_distance(set([x for x in str]), set([x for x in entity]))\n",
    "    print(f\"Entity: {entity} | Similarity: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given some list of entities, map names in output to each entity\n",
    "\n",
    "Aggregate the counts for each name into count for that entity\n",
    "\n",
    "\"Winner\" is entity with highest count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 24 (2402185589.py, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[16], line 28\u001b[1;36m\u001b[0m\n\u001b[1;33m    if len(candidate_entities) == 0: continue\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'for' statement on line 24\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "\n",
    "# data structure -> entity : [different names]\n",
    "entity_names = {key: [] for key in ENTITIES}\n",
    "\n",
    "# data structure -> entity : count\n",
    "entity_count = {key: 0 for key in ENTITIES} \n",
    "\n",
    "winners = sorted(output[\"Winner\"], key=lambda x: x[\"Number of Tweets\"], reverse=True)\n",
    "\n",
    "# traverse names in winners\n",
    "for i in range(len(winners)):\n",
    "    winner_info = winners[i] # name & tweet count\n",
    "    winner_name = winner_info[\"Name\"]\n",
    "    winner_count = winner_info[\"Number of Tweets\"]\n",
    "\n",
    "    # print(winner_info)\n",
    "    \n",
    "    # identify entities \"closest\" to winner_name - replace token_overlap w/ any similarity metric\n",
    "    candidate_entities = token_overlap(winner_name, classes=ENTITIES)         \n",
    "        \n",
    "    # don't map if no entity recognized\n",
    "    if len(candidate_entities) == 0: continue\n",
    "    \n",
    "    # typically single candidate identified, but in case multiple top candidates named pick random - should probably change\n",
    "    identified_entity = random.choice(candidate_entities) \n",
    "    \n",
    "    # print(f\"Name: {winner_name} | Candidate entities: {candidate_entities} | Identified entity: {identified_entity}\")\n",
    "\n",
    "    # map name to entity, update entity count\n",
    "    entity_names[identified_entity].append(winner_name)\n",
    "    entity_count[identified_entity] += winner_count\n",
    "\n",
    "    \n",
    "\n",
    "# winner = entity w/ highest count\n",
    "dict(sorted(entity_count.items(), key=lambda item: item[1], reverse=True))\n",
    "# print(entity_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation ideas)\n",
    "- consider proximity in text: words/names mentioned in close succession are likely related\n",
    "- entities are of a certain type: necessary for type checking\n",
    "\n",
    "Incorporate type checking in entity mapping:\n",
    "- how to implement?\n",
    "    - what to check correct \"type\" against? List of awards/movies/people?\n",
    "    - these lists can be imported into the repo? use external database? \n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keywords associated with different roles?\n",
    "- Hosts: starting, hosting\n",
    "- Awards: best (assumed)\n",
    "\n",
    "Mining award names:\n",
    "- syntactic parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df[df['cleaned_text'].str.contains('best')]['cleaned_text']\n",
    "\n",
    "# df[df[['cleaned_text']].str.contains('hosting')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting award names:\n",
    "- Identify categories - what does that mean? Need to extract entirety of award name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import nltk\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# df = pd.read_csv(Path(globals()['_dh'][0])/'Data'/'csvFile')\n",
    "gg2013answers_path = os.path.join(os.path.dirname(os.path.abspath('')), 'data', 'gg2013answers.json')\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open(gg2013answers_path, 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pathlib import Path\n",
    "\n",
    "# df = pd.read_csv(Path(globals()['_dh'][0])/'Data'/'csvFile')\n",
    "gg2013answers_path = os.path.join(os.path.dirname(os.path.abspath('')), 'data', 'gg2013answers.json')\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open(gg2013answers_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "awards_list = list(data['award_data'].keys())\n",
    "\n",
    "spacy_model = spacy.load('en_core_web_sm')\n",
    "\n",
    "# vary input statement w/ different award names\n",
    "# check recognition performance\n",
    "for award in awards_list:\n",
    "    print(f\"AWARD: {award}\")\n",
    "    input_sentence = 'I just heard Ben Affeck won ' + str(award) + ' and he was beyond grateful!'\n",
    "\n",
    "    text = word_tokenize(input_sentence)\n",
    "    print(nltk.pos_tag(text))\n",
    "    \n",
    "    # spacy_output = spacy_model(input_sentence)\n",
    "\n",
    "    # for chunk in spacy_output.noun_chunks:\n",
    "    #     print([chunk.text, chunk.root.head.text])\n",
    "    # print('\\n')\n",
    "\n",
    "    # for token in spacy_output:\n",
    "    #     print(\n",
    "    #     token.text,\n",
    "    #     token.dep_,\n",
    "    #     token.head.text,\n",
    "    #     token.head.pos_,\n",
    "    #     [child for child in token.children]\n",
    "    #     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type checking movie vs. human awards)\n",
    "- just check whether candidate entity is human\n",
    "\n",
    "Type checking against movies/credits data)\n",
    "- data contains many movies w/ cast & crew for each of those movies\n",
    "- winners/nominees must be entities that exist in the cast/crew for those movies\n",
    "    - extract cast for each movie (top N?) and store in db\n",
    "    - check against this list when identifying entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimin\\AppData\\Local\\Temp\\ipykernel_8944\\1790623868.py:6: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_df = pd.read_csv(movies_metadata_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "movies_metadata_path = os.path.join(os.path.dirname(os.path.abspath('')), 'data', 'movies_metadata.csv')\n",
    "credits_path = os.path.join(os.path.dirname(os.path.abspath('')), 'data', 'credits.csv')\n",
    "\n",
    "movies_df = pd.read_csv(movies_metadata_path)\n",
    "credits_df = pd.read_csv(credits_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "\n",
    "# create combined df w/ movies & credits\n",
    "# FILTER: for 'Released' & relevant year\n",
    "def create_movies_credits_df(year):\n",
    "    # declare file paths\n",
    "    movies_metadata_path = os.path.join(os.path.dirname(os.path.abspath('')), 'data', 'movies_metadata.csv')\n",
    "    credits_path = os.path.join(os.path.dirname(os.path.abspath('')), 'data', 'credits.csv')\n",
    "\n",
    "    movies = pd.read_csv(movies_metadata_path)\n",
    "    credits = pd.read_csv(credits_path)\n",
    "\n",
    "    # filter to 'Released' movies only\n",
    "    movies = movies[movies['status']=='Released']\n",
    "    \n",
    "    # remove unnecessary columns\n",
    "    movies.drop(columns=['belongs_to_collection', 'budget', 'homepage', 'imdb_id', 'overview', 'poster_path', 'runtime', 'status', 'tagline', 'video'], inplace=True)\n",
    "    # function to check int id types\n",
    "    def is_integer(val):\n",
    "        try:\n",
    "            # try to convert to int\n",
    "            int(val)\n",
    "            return True\n",
    "        except (ValueError, TypeError):\n",
    "            return False\n",
    "\n",
    "    # filter rows where 'id' is an integer-like value\n",
    "    movies = movies[movies.id.apply(is_integer)]\n",
    "\n",
    "    # convert 'id' column to int\n",
    "    movies.id = movies.id.astype(int)\n",
    "\n",
    "    # merge with credits df\n",
    "    df = pd.merge(movies, credits, on='id')\n",
    "    df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "    # clean columns\n",
    "    cols = ['genres', 'production_companies', 'production_countries', 'spoken_languages']\n",
    "    for col in cols:\n",
    "        df[col] = df[col].apply(extract_names)\n",
    "    df.release_date = pd.to_datetime(df.release_date)\n",
    "    df.cast = df.cast.apply(clean_cast_data)\n",
    "    df.crew = df.crew.apply(clean_crew_data)\n",
    "\n",
    "    # filter movie/credit data for relevant year\n",
    "    df = df[df['release_date'].dt.year == year]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# extract the category names\n",
    "def extract_names(name_str):\n",
    "    if pd.isna(name_str):\n",
    "        return []\n",
    "    # convert the string representation of the list to an actual list\n",
    "    str_list = ast.literal_eval(name_str)\n",
    "    # extract the 'name' from each dictionary in the list\n",
    "    names = [i['name'] for i in str_list]\n",
    "    # return list of names as a string\n",
    "    return ', '.join(names)\n",
    "\n",
    "# clean the cast data\n",
    "def clean_cast_data(cast_str):\n",
    "    # convert string representation of the list to an actual list\n",
    "    cast_list = ast.literal_eval(cast_str)\n",
    "\n",
    "    # extract relevant fields and change gender values\n",
    "    cleaned_cast = []\n",
    "    for member in cast_list:\n",
    "        cleaned_member = {\n",
    "            'character': member['character'],\n",
    "            'gender': 'm' if member['gender'] == 2 else 'f' if member['gender'] == 1 else None,\n",
    "            'name': member['name'],\n",
    "            'order': member['order']\n",
    "        }\n",
    "        cleaned_cast.append(cleaned_member)\n",
    "    return cleaned_cast\n",
    "\n",
    "# clean the crew data\n",
    "def clean_crew_data(crew_str):\n",
    "    # convert string representation of the list to an actual list\n",
    "    crew_list = ast.literal_eval(crew_str)\n",
    "\n",
    "    # extract relevant fields\n",
    "    cleaned_crew = []\n",
    "    for member in crew_list:\n",
    "        cleaned_member = {\n",
    "            'job': member['job'],\n",
    "            'name': member['name']\n",
    "        }\n",
    "        cleaned_crew.append(cleaned_member)\n",
    "    return cleaned_crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jimin\\AppData\\Local\\Temp\\ipykernel_8944\\3942010818.py:12: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies = pd.read_csv(movies_metadata_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>genres</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>False</td>\n",
       "      <td>Comedy, Horror</td>\n",
       "      <td>en</td>\n",
       "      <td>The Sleepover</td>\n",
       "      <td>0.135596</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2013-10-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>The Sleepover</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[{'character': 'Rachel', 'gender': None, 'name...</td>\n",
       "      <td>[{'job': 'Director', 'name': 'Chris Cullari'}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4341</th>\n",
       "      <td>False</td>\n",
       "      <td>Drama</td>\n",
       "      <td>fr</td>\n",
       "      <td>Camille Claudel 1915</td>\n",
       "      <td>0.134014</td>\n",
       "      <td>Canal+, Arte France Cinéma, 3B Productions, C....</td>\n",
       "      <td>France</td>\n",
       "      <td>2013-03-13</td>\n",
       "      <td>115860.0</td>\n",
       "      <td>Français</td>\n",
       "      <td>Camille Claudel 1915</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>[{'character': 'Camille Claudel', 'gender': 'f...</td>\n",
       "      <td>[{'job': 'Director', 'name': 'Bruno Dumont'}, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4342</th>\n",
       "      <td>False</td>\n",
       "      <td>Drama</td>\n",
       "      <td>fr</td>\n",
       "      <td>Camille Claudel 1915</td>\n",
       "      <td>0.134014</td>\n",
       "      <td>Canal+, Arte France Cinéma, 3B Productions, C....</td>\n",
       "      <td>France</td>\n",
       "      <td>2013-03-13</td>\n",
       "      <td>115860.0</td>\n",
       "      <td>Français</td>\n",
       "      <td>Camille Claudel 1915</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>[{'character': 'Camille Claudel', 'gender': 'f...</td>\n",
       "      <td>[{'job': 'Producer', 'name': 'Rachid Bouchareb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11215</th>\n",
       "      <td>False</td>\n",
       "      <td>Drama</td>\n",
       "      <td>en</td>\n",
       "      <td>La Cicatrice</td>\n",
       "      <td>0.025665</td>\n",
       "      <td>Cicatrice Film inc</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2013-03-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Français</td>\n",
       "      <td>The Scar</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'character': 'Richard Tremblay', 'gender': '...</td>\n",
       "      <td>[{'job': 'Director', 'name': 'Jimmy Larouche'}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14724</th>\n",
       "      <td>False</td>\n",
       "      <td>Animation</td>\n",
       "      <td>en</td>\n",
       "      <td>Dante's Hell Animated</td>\n",
       "      <td>0.787493</td>\n",
       "      <td>Dante's Inferno Animation</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>2013-11-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Italiano</td>\n",
       "      <td>Dante's Hell Animated</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[{'character': 'Circles Introduction (voice)',...</td>\n",
       "      <td>[{'job': 'Director', 'name': 'Boris Acosta'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       adult          genres original_language         original_title  \\\n",
       "1079   False  Comedy, Horror                en          The Sleepover   \n",
       "4341   False           Drama                fr   Camille Claudel 1915   \n",
       "4342   False           Drama                fr   Camille Claudel 1915   \n",
       "11215  False           Drama                en           La Cicatrice   \n",
       "14724  False       Animation                en  Dante's Hell Animated   \n",
       "\n",
       "      popularity                               production_companies  \\\n",
       "1079    0.135596                                                      \n",
       "4341    0.134014  Canal+, Arte France Cinéma, 3B Productions, C....   \n",
       "4342    0.134014  Canal+, Arte France Cinéma, 3B Productions, C....   \n",
       "11215   0.025665                                 Cicatrice Film inc   \n",
       "14724   0.787493                          Dante's Inferno Animation   \n",
       "\n",
       "           production_countries release_date   revenue spoken_languages  \\\n",
       "1079                              2013-10-12       0.0                    \n",
       "4341                     France   2013-03-13  115860.0         Français   \n",
       "4342                     France   2013-03-13  115860.0         Français   \n",
       "11215                    Canada   2013-03-03       0.0         Français   \n",
       "14724  United States of America   2013-11-25       0.0         Italiano   \n",
       "\n",
       "                       title  vote_average  vote_count  \\\n",
       "1079           The Sleepover           8.0         1.0   \n",
       "4341    Camille Claudel 1915           7.0        20.0   \n",
       "4342    Camille Claudel 1915           7.0        20.0   \n",
       "11215               The Scar           0.0         0.0   \n",
       "14724  Dante's Hell Animated           8.0         4.0   \n",
       "\n",
       "                                                    cast  \\\n",
       "1079   [{'character': 'Rachel', 'gender': None, 'name...   \n",
       "4341   [{'character': 'Camille Claudel', 'gender': 'f...   \n",
       "4342   [{'character': 'Camille Claudel', 'gender': 'f...   \n",
       "11215  [{'character': 'Richard Tremblay', 'gender': '...   \n",
       "14724  [{'character': 'Circles Introduction (voice)',...   \n",
       "\n",
       "                                                    crew  \n",
       "1079      [{'job': 'Director', 'name': 'Chris Cullari'}]  \n",
       "4341   [{'job': 'Director', 'name': 'Bruno Dumont'}, ...  \n",
       "4342   [{'job': 'Producer', 'name': 'Rachid Bouchareb...  \n",
       "11215  [{'job': 'Director', 'name': 'Jimmy Larouche'}...  \n",
       "14724      [{'job': 'Director', 'name': 'Boris Acosta'}]  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import sys\n",
    "# setting path\n",
    "# sys.path.append('../util_functions')\n",
    "\n",
    "# importing\n",
    "# from util_functions.movie_data_utils import create_movies_credits_df\n",
    "\n",
    "movies_credits_df = create_movies_credits_df(2013)\n",
    "\n",
    "movies_credits_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check movie cast & crew data\n",
    "\n",
    "Create DB with top N actors for each movie\n",
    "\n",
    "Check against this DB when identifying relevant entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>job</th>\n",
       "      <th>name</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>The Sleepover</td>\n",
       "      <td>Director</td>\n",
       "      <td>Chris Cullari</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4341</th>\n",
       "      <td>Camille Claudel 1915</td>\n",
       "      <td>Director</td>\n",
       "      <td>Bruno Dumont</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4341</th>\n",
       "      <td>Camille Claudel 1915</td>\n",
       "      <td>Writer</td>\n",
       "      <td>Bruno Dumont</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4341</th>\n",
       "      <td>Camille Claudel 1915</td>\n",
       "      <td>Producer</td>\n",
       "      <td>Rachid Bouchareb</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4341</th>\n",
       "      <td>Camille Claudel 1915</td>\n",
       "      <td>Producer</td>\n",
       "      <td>Jean Bréhat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     title       job              name   0\n",
       "1079         The Sleepover  Director     Chris Cullari NaN\n",
       "4341  Camille Claudel 1915  Director      Bruno Dumont NaN\n",
       "4341  Camille Claudel 1915    Writer      Bruno Dumont NaN\n",
       "4341  Camille Claudel 1915  Producer  Rachid Bouchareb NaN\n",
       "4341  Camille Claudel 1915  Producer       Jean Bréhat NaN"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe w cols: movie, and 'cast' dictionary mapped to separate columns\n",
    "\n",
    "# title & cast\n",
    "# cast_df = movies_credits_df[['title', 'cast']]\n",
    "# cast_df = cast_df.explode('cast')\n",
    "# cast_df['cast'].apply(pd.Series)\n",
    "# cast_df = pd.concat([cast_df, cast_df['cast'].apply(pd.Series)], axis=1).drop('cast', axis=1)\n",
    "\n",
    "\n",
    "crew_df = movies_credits_df[['title', 'crew']]\n",
    "crew_df = crew_df.explode('crew')\n",
    "crew_df['crew'].apply(pd.Series)\n",
    "crew_df = pd.concat([crew_df, crew_df['crew'].apply(pd.Series)], axis=1).drop('crew', axis=1)\n",
    "\n",
    "crew_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>character</th>\n",
       "      <th>gender</th>\n",
       "      <th>name</th>\n",
       "      <th>order</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>The Sleepover</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>None</td>\n",
       "      <td>Josh Feldman</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>The Sleepover</td>\n",
       "      <td>Eric</td>\n",
       "      <td>m</td>\n",
       "      <td>Gus Kamp</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>The Sleepover</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>None</td>\n",
       "      <td>Carolyn Jania</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>The Sleepover</td>\n",
       "      <td>Mrs. Roberts</td>\n",
       "      <td>None</td>\n",
       "      <td>Kristine Blackburn</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>The Sleepover</td>\n",
       "      <td>The Slasher</td>\n",
       "      <td>None</td>\n",
       "      <td>Walker Davis</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45001</th>\n",
       "      <td>Іван Сила</td>\n",
       "      <td>Pandorsky</td>\n",
       "      <td>None</td>\n",
       "      <td>Igor Pismennyy</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45001</th>\n",
       "      <td>Іван Сила</td>\n",
       "      <td>Kovalskiy</td>\n",
       "      <td>None</td>\n",
       "      <td>Bogdan Benyuk</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45001</th>\n",
       "      <td>Іван Сила</td>\n",
       "      <td>Adeliya</td>\n",
       "      <td>None</td>\n",
       "      <td>Olga Sumskaya</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45001</th>\n",
       "      <td>Іван Сила</td>\n",
       "      <td>Loader</td>\n",
       "      <td>None</td>\n",
       "      <td>Oleg Primogenov</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45001</th>\n",
       "      <td>Іван Сила</td>\n",
       "      <td>Red Clown</td>\n",
       "      <td>m</td>\n",
       "      <td>Boris Barsky</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14169 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               title     character gender                name  order   0\n",
       "1079   The Sleepover        Rachel   None        Josh Feldman    0.0 NaN\n",
       "1079   The Sleepover          Eric      m            Gus Kamp    1.0 NaN\n",
       "1079   The Sleepover        Rachel   None       Carolyn Jania    2.0 NaN\n",
       "1079   The Sleepover  Mrs. Roberts   None  Kristine Blackburn    3.0 NaN\n",
       "1079   The Sleepover   The Slasher   None        Walker Davis    4.0 NaN\n",
       "...              ...           ...    ...                 ...    ...  ..\n",
       "45001      Іван Сила     Pandorsky   None      Igor Pismennyy    4.0 NaN\n",
       "45001      Іван Сила     Kovalskiy   None       Bogdan Benyuk    5.0 NaN\n",
       "45001      Іван Сила       Adeliya   None       Olga Sumskaya    6.0 NaN\n",
       "45001      Іван Сила        Loader   None     Oleg Primogenov    7.0 NaN\n",
       "45001      Іван Сила     Red Clown      m        Boris Barsky    8.0 NaN\n",
       "\n",
       "[14169 rows x 6 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter to top 10 actors for each film\n",
    "cast_df[cast_df['order']<=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweet_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
